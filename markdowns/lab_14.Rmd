---
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

# LAB 14: Functional Data Analysis

## Smoothing

```{r echo=FALSE}
rm(list = ls())
```

Partly based on Ramsay, Hooker, Graves, "Functional Data Analysis with R and MATLAB", Springer, 2009. Part of the codes are courtesy of Prof. Laura Maria Sangalli.

Upload noisy data (with noise).

```{r }
noisycurve <- read.table(here::here('markdowns','lab_14_data',"noisycurvebis.txt"), header=TRUE)
head(noisycurve)
dim(noisycurve)

Xobs0 <- noisycurve$X0
abscissa <- noisycurve$Abscissa
NT <- length(abscissa) # number of locations of observations

plot(abscissa, Xobs0, xlab="t", ylab="observed data")
```

Upload true data (without noise).

X0 contains the values of the true curve
X1 contains the values of the true first derivative
X2 contains the values of the true second derivative

```{r }
truecurve <- read.table(here::here('markdowns','lab_14_data',"truecurve.txt"), header=TRUE)
head(truecurve)

plot(abscissa, Xobs0, xlab="t", ylab="observed data", type="l")
lines(abscissa, truecurve$X0vera, col=2, lwd=2)
```

Compute the central finite differences

```{r }
rappincX1 <- (Xobs0[3:NT]-Xobs0[1:(NT-2)])/(abscissa[3:NT]-abscissa[1:(NT-2)])
rappincX2 <- ((Xobs0[3:NT]-Xobs0[2:(NT-1)])/(abscissa[3:NT]-abscissa[2:(NT-1)])-(Xobs0[2:(NT-1)]-Xobs0[1:(NT-2)])/(abscissa[2:(NT-1)]-abscissa[1:(NT-2)]))*2/(abscissa[3:(NT)]-abscissa[1:(NT-2)])

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data", type='l', main="function")
points(truecurve$Abscissa, truecurve$X0vera, type='l', col="orange", lwd=3)
legend("topleft", legend=c("noisy data", "true curve"), col=c("black", "orange"), lwd=c(1, 2))
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l", main="1st derivative")
points(truecurve$Abscissa, truecurve$X1vera, type='l', col="orange", lwd=3)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l", main="2nd derivative")
points(truecurve$Abscissa, truecurve$X2vera, type='l', col="orange", lwd=3)
```


### Regression Splines

Load package `fda`

```{r message=FALSE}
library(fda)
```

Set parameters

```{r }
norder <- 5      # spline order (4th order polynomials)
degree <- norder-1    # spline degree
nbasis <- 9      # how many basis we want
```

Create the basis

```{r }
help(create.bspline.basis)
basis <- create.bspline.basis(rangeval=c(0, 1),
                              nbasis=nbasis,
                              norder=norder)
```

If breaks are not provided, equally spaced knots are created

```{r }
names(basis)

par(mfrow=c(1,1))
plot(basis)
```

Evaluate the basis on the grid of abscissa

```{r }
basismat <- eval.basis(abscissa, basis)
dim(basismat) # number of data x number of basis
head(basismat)
```

Fit via LS

```{r }
help(lsfit)

est_coef <- lsfit(basismat, Xobs0, intercept=FALSE)$coef
est_coef

Xsp0 <- basismat %*% est_coef

par(mfrow=c(1, 1))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsp0, type="l", col="blue", lwd=2)
abline(v=basis$params)
```

To obtain the first derivative (argument `Lfdobj=1`)

```{r }
basismat1 <- eval.basis(abscissa, basis, Lfdobj=1)
Xsp1 <- basismat1 %*% est_coef
```

To obtain the second derivative (argument `Lfdobj=2`)

```{r }
basismat2 <- eval.basis(abscissa, basis, Lfdobj=2)
Xsp2 <- basismat2 %*% est_coef

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, truecurve$X0vera, type="l", col="orange", lwd=3)
points(abscissa, Xsp0, type="l", col="blue", lwd=2)
legend("topleft", legend=c("noisy data", "true curve", "estimated curve"), col=c("black", "orange", "blue"), lwd=c(1, 3, 2))
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(truecurve$Abscissa, truecurve$X1vera, type='l', col="orange", lwd=3)
points(abscissa, Xsp1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(truecurve$Abscissa, truecurve$X2vera, type='l', col="orange", lwd=3)
points(abscissa, Xsp2, type="l", col="blue", lwd=2)
```

Alternative code

```{r }
help(smooth.basis)
Xsp <- smooth.basis(argvals=abscissa, y=Xobs0, fdParobj=basis)
Xsp0bis <- eval.fd(abscissa, Xsp$fd) #  the curve smoothing the data
Xsp1bis <- eval.fd(abscissa, Xsp$fd, Lfd=1) # first derivative
Xsp2bis <- eval.fd(abscissa, Xsp$fd, Lfd=2) # second derivative
df <- Xsp$df   #  the degrees of freedom in the smoothing curve
df             #  for regression splines the df are the number of basis
```

#### Approximate pointwise confidence intervals

As in linear models, we can estimate the variance of $x(t)$ as $\sigma^2\cdot\mathrm{diag}[\phi\cdot(\phi'\phi)^{-1}(\phi)']$

```{r }
S <- basismat %*% solve(t(basismat) %*% basismat) %*% t(basismat) #projection operator
sum(diag(S))
sigmahat <- sqrt(sum((Xsp0-Xobs0)^2)/(NT-df)) # estimate of sigma
lb <- Xsp0-qnorm(0.975)*sigmahat*sqrt(diag(S)) # upper bound
ub <- Xsp0+qnorm(0.975)*sigmahat*sqrt(diag(S)) # lower bound

par(mfrow=c(1,1))
plot(abscissa, Xsp0, type="l", col="blue", lwd=2, ylab="")
points(abscissa, lb, type="l", col="blue", lty="dashed")
points(abscissa, ub, type="l", col="blue", lty="dashed")
points(abscissa, truecurve$X0vera, type="l")
```

#### Oversmoothing: number of basis too low

```{r }
nbasis <- 7

basisbis <- create.bspline.basis(c(0, 1), nbasis, norder)

par(mfrow=c(1, 1))
plot(basisbis)

basismatbis <- eval.basis(abscissa, basisbis)
est_coef_bis <- lsfit(basismatbis, Xobs0, intercept=FALSE)$coef
Xsp0bis <- basismatbis %*% est_coef_bis

basismat1bis <- eval.basis(abscissa, basisbis, Lfdobj=1)
Xsp1bis <- basismat1bis %*% est_coef_bis

basismat2bis <- eval.basis(abscissa, basisbis, Lfdobj=2)
Xsp2bis <- basismat2bis %*% est_coef_bis

par(mfrow=c(1, 1))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsp0bis, type="l", col="green", lwd=2)
abline(v=basisbis$params, lty=2)

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsp0bis, type="l", col="green", lwd=2)
points(abscissa, Xsp0, type="l", col="blue", lwd=2)
legend("topleft", legend=c("noisy data", "estimate df=7", "estimate df=9"), col=c("black", "green", "blue"), lwd=c(1, 2, 2))
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xsp1bis, type="l", col="green", lwd=2)
points(abscissa, Xsp1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xsp2bis, type="l", col="green", lwd=2)
points(abscissa, Xsp2, type="l", col="blue", lwd=2)
```

#### Undersmoothing: number of basis too high

```{r }
nbasis <- 30

basister <- create.bspline.basis(c(0, 1), nbasis, norder)
par(mfrow=c(1, 1))
plot(basister)

basismatter <- eval.basis(abscissa, basister)
est_coef_ter <- lsfit(basismatter, Xobs0, intercept=FALSE)$coef
Xsp0ter <- basismatter %*% est_coef_ter

basismat1ter <- eval.basis(abscissa, basister, Lfdobj=1)
Xsp1ter <- basismat1ter %*% est_coef_ter

basismat2ter <- eval.basis(abscissa, basister, Lfdobj=2)
Xsp2ter <- basismat2ter %*% est_coef_ter

par(mfrow=c(1, 1))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsp0ter, type="l", col="red", lwd=2)
abline(v=basister$params, lty=2)

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsp0ter, type="l", col="red", lwd=2)
points(abscissa, Xsp0bis, type="l", col="green", lwd=2)
points(abscissa, Xsp0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xsp1ter, type="l", col="red", lwd=2)
points(abscissa, Xsp1bis, type="l", col="green", lwd=2)
points(abscissa, Xsp1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xsp2ter, type="l", col="red", lwd=2)
points(abscissa, Xsp2bis, type="l", col="green", lwd=2)
points(abscissa, Xsp2, type="l", col="blue", lwd=2)
```

Generalized cross-validation

```{r }
nbasis <- 6:30
gcv <- numeric(length(nbasis))
for (i in 1:length(nbasis)){
  basis <- create.bspline.basis(c(0, 1), nbasis[i], norder)
  gcv[i] <- smooth.basis(abscissa, Xobs0, basis)$gcv
}
par(mfrow=c(1, 1))
plot(nbasis, gcv)
nbasis[which.min(gcv)]
abline(v=nbasis[which.min(gcv)], col=2)
```

#### Bias-Variance trade-off

```{r }
sigma <- 0.003 # True sigma. Estimated before as sigmahat
nbasis <- 9:15
integrationinterval <- 11:90
bias <- rep(NA, len=length(nbasis))
var <- rep(NA, len=length(nbasis))
for (j in 1:length(nbasis)){
  basis <- create.bspline.basis(c(0, 1), nbasis[j], norder)
  basismat <- eval.basis(abscissa, basis)
  S <- basismat %*% solve(t(basismat) %*% basismat) %*% t(basismat)
  bias[j] <- sum((truecurve$X0vera-S %*% truecurve$X0vera)[integrationinterval])
  var[j] <- (sigma^2)*sum(diag(S[integrationinterval, integrationinterval]))
}
mse <- var+bias^2

par(mfrow=c(1, 1))
plot(nbasis, bias^2, ylim=c(0, max(mse)), type="l", ylab="", main="Bias-Variance tradeoff")
points(nbasis, var, col="red", type="l")
points(nbasis, mse, col="green", type="l", lwd=3)
legend('topright', c("Bias", "Var", "MSE"), col=c("black", "red", "green"),
       lty=1, cex=.5)
```

### Smoothing Splines

```{r }
# breaks <- abscissa[((0:50)*2)+1]
breaks <- abscissa

basis <- create.bspline.basis(breaks, norder=norder)
functionalPar <- fdPar(fdobj=basis, Lfdobj=3, lambda=1e-8)
```

Functional parameter, having arguments: basis, order of the derivative to be penalized, smoothing parameter.

```{r }
Xss <- smooth.basis(abscissa, Xobs0, functionalPar)

Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)

df <- Xss$df    #  the degrees of freedom in the smoothing curve
df
gcv <- Xss$gcv  #  the value of the gcv statistic
gcv

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xss0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xss1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xss2, type="l", col="blue", lwd=2)
```

Change `lambda`: 1e-5

```{r }
functionalParbis <- fdPar(fdobj=basis, Lfdobj=3, lambda=1e-5)

Xssbis <- smooth.basis(abscissa, Xobs0, functionalParbis)

Xss0bis <- eval.fd(abscissa, Xssbis$fd, Lfd=0)
Xss1bis <- eval.fd(abscissa, Xssbis$fd, Lfd=1)
Xss2bis <- eval.fd(abscissa, Xssbis$fd, Lfd=2)

dfbis <- Xssbis$df    #  the degrees of freedom in the smoothing curve
dfbis
gcvbis <- Xssbis$gcv  #  the value of the gcv statistic
gcvbis
```

Change `lambda`: 1e-12

```{r }
functionalParter <- fdPar(fdobj=basis, Lfdobj=3, lambda=1e-12)

Xsster <- smooth.basis(abscissa, Xobs0, functionalParter)

Xss0ter <- eval.fd(abscissa, Xsster$fd, Lfd=0)
Xss1ter <- eval.fd(abscissa, Xsster$fd, Lfd=1)
Xss2ter <- eval.fd(abscissa, Xsster$fd, Lfd=2)

dfter <- Xsster$df    #  the degrees of freedom in the smoothing curve
dfter
gcvter <- Xsster$gcv  #  the value of the gcv statistic
gcvter

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xss0ter, type="l", col="red", lwd=2)
points(abscissa, Xss0bis, type="l", col="green", lwd=2)
points(abscissa, Xss0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xss1ter, type="l", col="red", lwd=2)
points(abscissa, Xss1bis, type="l", col="green", lwd=2)
points(abscissa, Xss1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xss2ter, type="l", col="red", lwd=2)
points(abscissa, Xss2bis, type="l", col="green", lwd=2)
points(abscissa, Xss2, type="l", col="blue", lwd=2)
```

Recommendation: when choosing the smoothing parameter, look at the derivatives vs central finite differences.

#### Generalized cross-validation.

```{r }
lambda <- 10^seq(-12, -5, by=0.5)
gcv <- numeric(length(lambda))
for (i in 1:length(lambda)){
  functionalPar <- fdPar(fdobj=basis, Lfdobj=3, lambda=lambda[i])
  gcv[i] <- smooth.basis(abscissa, Xobs0, functionalPar)$gcv
}
par(mfrow=c(1, 1))
plot(log10(lambda), gcv)
lambda[which.min(gcv)]
```

Best lambda

```{r }
functionalParbest <- fdPar(fdobj=basis, Lfdobj=3, lambda=lambda[which.min(gcv)])

Xssbest <- smooth.basis(abscissa, Xobs0, functionalParbest)

Xss0best <- eval.fd(abscissa, Xssbest$fd, Lfd=0)
Xss1best <- eval.fd(abscissa, Xssbest$fd, Lfd=1)
Xss2best <- eval.fd(abscissa, Xssbest$fd, Lfd=2)

dfbest <- Xssbest$df    #  the degrees of freedom in the smoothing curve
dfbest
gcvbest <- Xssbest$gcv  #  the value of the gcv statistic
gcvbest

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xss0ter, type="l", col="red", lwd=1)
points(abscissa, Xss0bis, type="l", col="green", lwd=1)
points(abscissa, Xss0best, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xss1ter, type="l", col="red", lwd=1)
points(abscissa, Xss1bis, type="l", col="green", lwd=1)
points(abscissa, Xss1best, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xss2ter, type="l", col="red", lwd=1)
points(abscissa, Xss2bis, type="l", col="green", lwd=1)
points(abscissa, Xss2best, type="l", col="blue", lwd=2)
```

### Local Polynomial Regression

```{r message=FALSE}
library(KernSmooth)
```

```{r }
help(locpoly)

m <- 5           # order of the polynomial
degree <- m-1    # degree of the polynomial


bw <- 0.05 # bandwidth

Xsm0 <- locpoly(abscissa, Xobs0, degree=degree,
                bandwidth=bw, gridsize=length(abscissa),
                range.x=range(abscissa))
Xsm0 <- Xsm0$y


par(mfrow=c(1, 1))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsm0, type="l", col="blue")
```

Estimate of the derivatives

```{r }
Xsm1 <- locpoly(abscissa, Xobs0, drv=1, degree=degree, bandwidth=bw,
                gridsize=length(abscissa), range.x=range(abscissa))
Xsm1 <- Xsm1$y

Xsm2 <- locpoly(abscissa, Xobs0, drv=2, degree=degree, bandwidth=bw,
                gridsize=length(abscissa), range.x=range(abscissa))
Xsm2 <- Xsm2$y

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsm0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xsm1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xsm2, type="l", col="blue", lwd=2)
```

Changing the bandwidth: larger value

```{r }
bw <- 0.15

Xsm0bis <- locpoly(abscissa, Xobs0, drv=0, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm0bis <- Xsm0bis$y

Xsm1bis <- locpoly(abscissa, Xobs0, drv=1, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm1bis <- Xsm1bis$y

Xsm2bis <- locpoly(abscissa, Xobs0, drv=2, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm2bis <- Xsm2bis$y


par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsm0bis, type="l", col="green", lwd=2)
points(abscissa, Xsm0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xsm1bis, type="l", col="green", lwd=2)
points(abscissa, Xsm1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xsm2bis, type="l", col="green", lwd=2)
points(abscissa, Xsm2, type="l", col="blue", lwd=2)
```

- **a too large bandwidth leads to oversmoothing**
- **a too small bandwidth leads to undersmoothing**

```{r }
bw <- 0.015

Xsm0ter <- locpoly(abscissa, Xobs0, drv=0, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm0ter <- Xsm0ter$y

Xsm1ter <- locpoly(abscissa, Xobs0, drv=1, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm1ter <- Xsm1ter$y

Xsm2ter <- locpoly(abscissa, Xobs0, drv=2, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm2ter <- Xsm2ter$y

par(mfrow=c(1, 3))
plot(abscissa, Xobs0, xlab="t", ylab="observed data")
points(abscissa, Xsm0ter, type="l", col="red", lwd=2)
points(abscissa, Xsm0bis, type="l", col="green", lwd=2)
points(abscissa, Xsm0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="t", ylab="first differences x", type="l")
points(abscissa, Xsm1ter, type="l", col="red", lwd=2)
points(abscissa, Xsm1bis, type="l", col="green", lwd=2)
points(abscissa, Xsm1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="t", ylab="second differences x", type="l")
points(abscissa, Xsm2ter, type="l", col="red", lwd=2)
points(abscissa, Xsm2bis, type="l", col="green", lwd=2)
points(abscissa, Xsm2, type="l", col="blue", lwd=2)
```

Recommendation: when choosing the bandwidth, look at the derivatives vs central finite differences.

### Constrained functions

#### Smoothing for positive curves

$$
y_j = e^{w(t_j)} + e_j \qquad f(t) = e^{w(t)}
$$

The function $w(t)$ is unconstrained.
The function $f(t)$ is positive.
$w(t)$ is modeled via a basis expansion.
Numerical methods are used to compute the coefficients of the basis expansion.

```{r }
help(smooth.pos)
```

#### Smoothing for monotone curves

Example: Berkeley growth data

```{r }
help(growth)
names(growth)

par(mfrow=c(1,2))
matplot(growth$age, growth$hgtf, type="l",
        xlab="Age", ylab="Female Height")
matplot(growth$age, growth$hgtm, type="l",
        xlab="Age", ylab="Male Height")
```

If we neglect considering that the curves must be monotone...

```{r }
age <- growth$age
heightbasis12 <- create.bspline.basis(rangeval=c(1, 18), nbasis=12, norder=6)
basismat <- eval.basis(evalarg=growth$age, basisobj=heightbasis12)
heightmat <- growth$hgtf
heightcoef <- lsfit(x=basismat, y=heightmat, intercept=FALSE)$coef

height <- basismat %*% lsfit(basismat, heightmat, intercept=FALSE)$coef

basismat1 <- eval.basis(evalarg=growth$age, basisobj=heightbasis12,
                         Lfdobj=1)
heightvelocity <- basismat1 %*% lsfit(x=basismat, y=heightmat,
                                   intercept=FALSE)$coef

basismat2 <- eval.basis(evalarg=growth$age, basisobj=heightbasis12, Lfdobj=2)
heightacceleration <- basismat2 %*% lsfit(x=basismat, y= heightmat, intercept=FALSE)$coef


par(mfrow=c(1, 3))
matplot(age, height, type="l" )
matplot(age, heightvelocity, type="l" )
abline(h=0)
matplot(age, heightacceleration, type="l")
```

```
par(mfrow=c(1, 3))
matplot(age, height, type="l" )
matplot(age[-c(1, 2, 3, 31)], heightvelocity[-c(1, 2, 3, 31), ], type="l" )
abline(h=0)
matplot(age[-c(1, 2, 3, 31)], heightacceleration[-c(1, 2, 3, 31), ], type="l")
```
A negative velocity does not make any sense (girls height does not decrease over this age interval).

A model for monotone curves
$$
f(t)=\int_{t_0}^t e^{w(u)} du \qquad
y_j = b_0 + b_1 \cdot f(t_j) + e_j
$$
The function $w(t)$ is unconstrained.
The function $f(t)$ is monotone increasing.

- $b_1>0$ for monotone increasing functions
- $b_1<0$ for monotone decreasing functions
- $b_0$ is the value of the function at $t_0$
- $w(t)$ is modeled via a basis expansion

Numerical methods are used to compute the coefficients of the basis expansion, as well as $b_0, b_1$.

```{r }
nage <- length(age)
ageRng <- range(age)
nfine <- 101
agefine <- seq(ageRng[1], ageRng[2], length=nfine)
```

Let's consider only the first 5 girls

```{r }
hgtf <- growth$hgtf[, 1:5]
ncasef <- dim(hgtf)[2]
```

We set up an order 6 spline basis with knots at ages of observations

```{r }
norder <- 6
nbasis <- nage - 2 + norder
wbasis <- create.bspline.basis(rangeval=ageRng, nbasis=nbasis,
                              norder=norder, breaks=age)
```

We construct the functional parameter with penalization of the third derivative

```{r }
Lfdobj <- 3
lambda <- 10^(-0.5)
cvecf <- matrix(0, nbasis, ncasef) # this is used as initial value
                                   # for the numerical techniques
Wfd0 <- fd(coef=cvecf, basisobj=wbasis)
growfdPar <- fdPar(fdobj=Wfd0, Lfdobj=Lfdobj, lambda=lambda)
```

We carry out a monotone smoothing

```{r }
help(smooth.monotone)

growthMon <- smooth.monotone(argvals=age, y=hgtf, WfdParobj=growfdPar)


Wfd <- growthMon$Wfd
betaf <- growthMon$beta
hgtfhatfd <- growthMon$yhatfd

velocfdUN <- deriv.fd(expr=hgtfhatfd, Lfdobj=1)
velocmeanfdUN <- mean.fd(velocfdUN)

accelfdUN <- deriv.fd(expr=hgtfhatfd, Lfdobj=2)
accelmeanfdUN <- mean.fd(accelfdUN)


par(mfrow=c(2, 2), mar=c(6, 5, 2, 1), mex=0.6, mgp=c(2.2, 0.7, 0), pty="m", font.main=1, font.lab=1, font.axis=1, cex.lab=1.3, cex.axis=1)
plot(hgtfhatfd, xlim=c(1, 18), lty=1, lwd=2,
     cex=2, xlab="Age", ylab="Growth (cm)")
plot(velocfdUN, xlim=c(1, 18), lty=1, lwd=2,
     cex=2, xlab="Age", ylab="Velocity (cm/yr)")
plot(accelfdUN, xlim=c(1, 18), ylim=c(-4, 3), lty=1, lwd=2,
     cex=2, xlab="Age", ylab="Acceleration (cm/yr/yr)")

plot(wbasis)
```

Extension to multidimensional curves

```{r }
noisycurve3D <- read.table(here::here('markdowns','lab_14_data',"noisycurve3D.txt"), header=TRUE)
Xobs0 <- noisycurve3D$X0
Yobs0 <- noisycurve3D$Y0
Zobs0 <- noisycurve3D$Z0
obs0 <- rbind(Xobs0, Yobs0, Zobs0)
abscissa <- noisycurve3D$Abscissa
NT <- length(abscissa)

truecurve3D <- read.table(here::here('markdowns','lab_14_data',"truecurve3D.txt"), header=TRUE)
Xtrue0 <- truecurve3D$X0
Ytrue0 <- truecurve3D$Y0
Ztrue0 <- truecurve3D$Z0
true0 <- rbind(Xtrue0, Ytrue0, Ztrue0)

library(rgl)

open3d()
lines3d(t(true0[1, ]), t(true0[2, ]), t(true0[3, ]), xlab="", ylab="", zlab="", size=3, axes=F)
points3d(t(obs0[1, ]), t(obs0[2, ]), t(obs0[3, ]), xlab="", ylab="", zlab="", size=2, axes=F, pch=19, cex=2)
box3d()
```

Compute the difference quotient

```{r }
rappincX1 <- (Xobs0[3:NT]-Xobs0[1:(NT-2)])/(abscissa[3:NT]-abscissa[1:(NT-2)])
rappincY1 <- (Yobs0[3:NT]-Yobs0[1:(NT-2)])/(abscissa[3:NT]-abscissa[1:(NT-2)])
rappincZ1 <- (Zobs0[3:NT]-Zobs0[1:(NT-2)])/(abscissa[3:NT]-abscissa[1:(NT-2)])

rappincX2 <- ((Xobs0[3:NT]-Xobs0[2:(NT-1)])/(abscissa[3:NT]-abscissa[2:(NT-1)])-(Xobs0[2:(NT-1)]-Xobs0[1:(NT-2)])/(abscissa[2:(NT-1)]-abscissa[1:(NT-2)]))*2/(abscissa[3:(NT)]-abscissa[1:(NT-2)])
rappincY2 <- ((Yobs0[3:NT]-Yobs0[2:(NT-1)])/(abscissa[3:NT]-abscissa[2:(NT-1)])-(Yobs0[2:(NT-1)]-Yobs0[1:(NT-2)])/(abscissa[2:(NT-1)]-abscissa[1:(NT-2)]))*2/(abscissa[3:(NT)]-abscissa[1:(NT-2)])
rappincZ2 <- ((Zobs0[3:NT]-Zobs0[2:(NT-1)])/(abscissa[3:NT]-abscissa[2:(NT-1)])-(Zobs0[2:(NT-1)]-Zobs0[1:(NT-2)])/(abscissa[2:(NT-1)]-abscissa[1:(NT-2)]))*2/(abscissa[3:(NT)]-abscissa[1:(NT-2)])


par(mfrow=c(3, 3), mar=c(6, 5, 2, 1), mex=0.6, mgp=c(2.2, 0.7, 0), pty="m", font.main=1, font.lab=1, font.axis=1, cex.lab=1.3, cex.axis=1)

plot(abscissa, obs0[1, ], xlab=expression(tilde(s)), ylab="observed data x", cex=0.1, asp=1)
plot(abscissa, obs0[2, ], xlab=expression(tilde(s)), ylab="observed data y", cex=0.1, asp=1)
plot(abscissa, obs0[3, ], xlab=expression(tilde(s)), ylab="observed data z", cex=0.1, asp=1)
plot(abscissa[2:(NT-1)], rappincX1, xlab=expression(tilde(s)), ylab="first differences x", type="l", asp=1)
plot(abscissa[2:(NT-1)], rappincY1, xlab=expression(tilde(s)), ylab="first differences y", type="l", asp=1)
plot(abscissa[2:(NT-1)], rappincZ1, xlab=expression(tilde(s)), ylab="first differences z", type="l", asp=1)
plot(abscissa[2:(NT-1)], rappincX2, xlab=expression(tilde(s)), ylab="second differences x", type="l")
plot(abscissa[2:(NT-1)], rappincY2, xlab=expression(tilde(s)), ylab="second differences y", type="l")
plot(abscissa[2:(NT-1)], rappincZ2, xlab=expression(tilde(s)), ylab="second differences z", type="l")


bw <- 0.05

Xsm0 <- locpoly(abscissa, Xobs0, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm0 <- Xsm0$y

Xsm1 <- locpoly(abscissa, Xobs0, drv=1, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm1 <- Xsm1$y

Xsm2 <- locpoly(abscissa, Xobs0, drv=2, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Xsm2 <- Xsm2$y


Ysm0 <- locpoly(abscissa, Yobs0, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Ysm0 <- Ysm0$y

Ysm1 <- locpoly(abscissa, Yobs0, drv=1, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Ysm1 <- Ysm1$y

Ysm2 <- locpoly(abscissa, Yobs0, drv=2, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Ysm2 <- Ysm2$y


Zsm0 <- locpoly(abscissa, Zobs0, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Zsm0 <- Zsm0$y

Zsm1 <- locpoly(abscissa, Zobs0, drv=1, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Zsm1 <- Zsm1$y

Zsm2 <- locpoly(abscissa, Zobs0, drv=2, degree=degree, bandwidth=bw, gridsize=length(abscissa), range.x=range(abscissa))
Zsm2 <- Zsm2$y



par(mfrow=c(3, 3), mar=c(6, 5, 2, 1), mex=0.6, mgp=c(2.2, 0.7, 0), pty="m", font.main=1, font.lab=1, font.axis=1, cex.lab=1.3, cex.axis=1)

plot(abscissa, obs0[1, ], xlab="s", ylab="x", cex=0.1, asp=1, xlim=c(0, 1))
points(abscissa, Xsm0, type="l", col="blue", lwd=2)
plot(abscissa, obs0[2, ], xlab="s", ylab="y", cex=0.1, asp=1, xlim=c(0, 1))
points(abscissa, Ysm0, type="l", col="blue", lwd=2)
plot(abscissa, obs0[3, ], xlab="s", ylab="z", cex=0.1, asp=1, xlim=c(0, 1))
points(abscissa, Zsm0, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX1, xlab="s", ylab="x'", type="l", ylim=c(-0.5, 0.5), xlim=c(0, 1))
points(abscissa, Xsm1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincY1, xlab="s", ylab="y'", type="l", ylim=c(-0.5, 0.5), xlim=c(0, 1))
points(abscissa, Ysm1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincZ1, xlab="s", ylab="z'", type="l", ylim=c(-0.5, 0.5), xlim=c(0, 1))
points(abscissa, Zsm1, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincX2, xlab="s", ylab="x''", type="l")
points(abscissa, Xsm2, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincY2, xlab="s", ylab="y''", type="l")
points(abscissa, Ysm2, type="l", col="blue", lwd=2)
plot(abscissa[2:(NT-1)], rappincZ2, xlab="s", ylab="z''", type="l")
points(abscissa, Zsm2, type="l", col="blue", lwd=2)


open3d()
lines3d(t(true0[1, ]), t(true0[2, ]), t(true0[3, ]), xlab="", ylab="", zlab="", size=3, axes=F)
points3d(t(obs0[1, ]), t(obs0[2, ]), t(obs0[3, ]), size=2, pch=19, cex=2)
lines3d(t(Xsm0), t(Ysm0), t(Zsm0), size=3, col="blue")
box3d()
```

Or we may use another among the techniques seen above.

Missing exam exercise here.

## K-mean Alignment (KMA)

Based on Sangalli, L.M., Secchi, P., Vantini, S., Vitelli, V., 2010. "K-mean alignment for curve clustering". Computational Statistics and Data Analysis, 54, 1219-1233.

Using the R package `fdakma`.

It's now deprecated, so run this code to install the last available version
```
install.packages("devtools") 
require(devtools) 
install_version("fdakma", version = "1.2.1", repos = "http://cran.r-project.org")
```

```{r }
rm(list=ls())
library(fdakma)
data(kma.data)

d <- kma.data
names(kma.data)

x <- d$x   # abscissas
y0 <- d$y0 # evaluations of original functions
y1 <- d$y1 # evaluations of original functions' first derivatives
```

Plot of original functions

```{r }
matplot(t(x), t(y0), type='l', xlab='x', ylab='orig.func')
title('Original functions')
```

There seems to be 3 clusters of functions obtained by warping the abscissas.

Plot of original function first derivatives

```{r }
matplot(t(x), t(y1), type='l', xlab='x', ylab='orig.deriv')
title ('Original function first derivatives')
```

Without alignment, let's try with 3 clusters

```{r warning=FALSE}
set.seed(4)
fdakma_example_noalign_0der <- kma(
  x=x, y0=y0, n.clust=3,
  warping.method='NOalignment',
  similarity.method='d0.pearson', # similarity computed as the cosine
                                  # between the original curves
                                  # (correlation)
  center.method='k-means'
  #, seeds=c(1, 11, 21) # you can give a little help to the algorithm...
)

# kma.show.results(fdakma_example_noalign_0der)
fdakma_example_noalign_0der$labels
```

We might want to use a similarity measure which considers first derivatives

```{r warning=FALSE}
set.seed(5)
fdakma_example_noalign_1der <- kma(
  x=x, y0=y0, y1=y1, n.clust=3,
  warping.method='NOalignment',
  similarity.method='d1.pearson',   # similarity computed as the cosine
                                      # between the first derivatives
                                      # (correlation)
  center.method='k-means'
  #, seeds=c(1, 11, 21) # you can give a little help to the algorithm...
)

# kma.show.results(fdakma_example_noalign_1der)
fdakma_example_noalign_1der$labels
```

Label switching aside, it is the same clustering

```{r }
table(fdakma_example_noalign_0der$labels,
      fdakma_example_noalign_1der$labels, dnn=c("0der", "1der"))
```

Let's allow for alignment. Result of `kma` with 2 clusters, allowing `affine` transformation for the abscissas and considering `d1.pearson` as `similarity.method`.

```{r warning=FALSE}
set.seed(1)
fdakma_example <- kma(
  x=x, y0=y0, y1=y1, n.clust=2,
  warping.method='affine',
  similarity.method='d1.pearson',  # similarity computed as the cosine
                                     # between the first derivatives
                                     # (correlation)
  center.method='k-means'
  #seeds=c(1, 21) # you can give a little help to the algorithm...
)

# kma.show.results(fdakma_example)
```

Much better: high within group similarity after alignment, the boxplot is concentrated on 1.

Labels assigned to each function

```{r }
fdakma_example$labels

table(fdakma_example_noalign_0der$labels,
      fdakma_example$labels,
      dnn=c("NOalign_0der_3groups", "Align_1der_2groups"))
```

Total shifts and dilations applied to the original abscissa to obtain the aligned abscissa

```{r }
fdakma_example$shift
fdakma_example$dilation
```

Warpings applied to the original data, colored according to membership to the 3 clusters obtained via `k-means`, no alignment, `d0.pearson` similarity.

```{r }
plot(x, type="n", xlim=c(min(x), max(x)), ylim=c(min(x), max(x)+2), xlab="abscissa", ylab="warping")
title("Alignment affinities")
for(i in 1:30)(
  abline(a=fdakma_example$shift[i], b=fdakma_example$dilation[i],
         col=fdakma_example_noalign_0der$labels[i])
)
```

How to choose the number of clusters and the warping method

```{r warning=FALSE}
kma.compare_example <- kma.compare (
  x=x, y0=y0, y1=y1, n.clust=1:3,
  warping.method=c('affine'),
  similarity.method='d1.pearson',
  center.method='k-means',
  seeds=c(1, 21, 30),
  plot.graph=TRUE)

kma.compare_example_2 <- kma.compare (
  x=x, y0=y0, y1=y1, n.clust=1:3,
  warping.method=c("shift", "dilation", "affine"),
  similarity.method='d1.pearson',
  center.method='k-means',
  seeds=c(1, 21, 30),
  plot.graph=TRUE)

kma.compare_example_3 <- kma.compare (
  x=x, y0=y0, y1=y1, n.clust=1:3,
  warping.method=c("NOalignment", "shift", "dilation", "affine"),
  similarity.method='d1.pearson',
  center.method='k-means',
  seeds=c(1, 21, 30),
  plot.graph=TRUE)
```

## Functional Principal Component Analysis (FPCA)

Partly based on Ramsay, Hooker, Graves, "Functional Data Analysis with R and Matlab", Springer, 2009. Part of the codes are courtesy of Prof. Alessia Pini.

```{r message=FALSE}
library(fda)
```

### First dataset: `CanadianWeather`

Daily temperatures recorded in 35 weather stations of Canada (data are averages over 35 years - 1960 to 1994)

```{r }
data_W <- CanadianWeather$dailyAv[, ,1]
head(data_W)
dim(data_W)
matplot(data_W, type='l', main='Canadian temperature', xlab='Day', ylab='Temperature')
```

First of all we smooth the data. We choose a Fourier basis (periodic). We need to set the dimension of the basis

```{r }
time <- 1:365
```

**Choice 1**: we set a high dimensional basis (interpolating)

- Pros: no loss of information
- Cons: possible overfitting

```{r }
basis.1 <- create.fourier.basis(rangeval=c(0, 365), nbasis=365)
data_W.fd.1 <- Data2fd(y=data_W, argvals=time, basisobj=basis.1)
plot.fd(data_W.fd.1)
```

**Choice 2**: reduced dimensionality (we set a low dimensional basis)

- Pros: the data are much smoother and the measurement error is filtered
- Cons: I could have lost important information

```{r }
basis.2 <- create.fourier.basis(rangeval=c(0, 365), nbasis=21)
data_W.fd.2 <- Data2fd(y=data_W, argvals=time, basisobj=basis.2)
plot.fd(data_W.fd.2)
```

**Choice 3**: compromise between 1 and 2

```{r }
basis.3 <- create.fourier.basis(rangeval=c(0, 365), nbasis=109)
data_W.fd.3 <- Data2fd(y=data_W, argvals=time, basisobj=basis.3)
plot.fd(data_W.fd.3)
```

Estimate of the mean and of the covariance kernel

```{r message=FALSE}
library(fields)
```

```{r }
# Mean

par(mfrow=c(2, 3))
plot.fd(data_W.fd.1)
lines(mean.fd(data_W.fd.1), lwd=3)

plot.fd(data_W.fd.2)
lines(mean.fd(data_W.fd.2), lwd=2)

plot.fd(data_W.fd.3)
lines(mean.fd(data_W.fd.3), lwd=2)

# Covariance

eval.1 <- eval.fd(time, data_W.fd.1)
image.plot(time, time, (cov(t(eval.1))[1:365, ]))

eval.2 <- eval.fd(time, data_W.fd.2)
image.plot(time, time, (cor(t(eval.2))[1:365, ]))

eval.3 <- eval.fd(time, data_W.fd.3)
image.plot(time, time, (cov(t(eval.3))[1:365, ]))
```

### Second dataset: `lip`

51 measurements of the position of the lower lip every 7 milliseconds for 20 repetitions of the syllable 'bob'.

```{r }
data_L <- lip
length(data_L)

time <- seq(0, 350, by=7)

par(mfrow=c(1,1))
matplot(time, data_L, type='l', main='Lip data',
        ylab='Position', xlab='Time (millisec.)')
```

In this case, the data are already quite smooth. The smoothing does not pose problems. Since the Fourier basis creates periodical data, it modifies the data near the boundaries of the domain, to make them periodical

```{r }
basis <- create.fourier.basis(rangeval=c(0, 350), nbasis=51)
data_L.fd <- Data2fd(data_L, time, basis)

plot.fd(data_L.fd, main="Fourier")
```

Better to use a b-spline basis

```{r }
basis <- create.bspline.basis(rangeval=c(0, 350), nbasis=21)
data_L.fd <- Data2fd(y=data_L, argvals=time, basisobj=basis)
plot.fd(data_L.fd, main="B-splines")
```

Estimate of the mean and of the covariance kernel

```{r }
layout(cbind(1, 2))
plot.fd(data_L.fd, xaxs='i')
lines(mean.fd(data_L.fd), lwd=2)
eval <- eval.fd(time, data_L.fd)
image.plot(time, time, (cov(t(eval))[1:51, ]))
```

### FPCA on `CanadianWeather`

```{r }
help(pca.fd)
```

#### Interpolated data (Choice 1)

```{r }
par(mfrow=c(1,1))
plot.fd(data_W.fd.1, ylab='temperature')

pca_W.1 <- pca.fd(data_W.fd.1, nharm=5, centerfns=TRUE)
```

Scree plot

`pca.fd` computes all the 365 eigenvalues, but only the first N-1=34 are non-null

```{r }
par(mfrow=c(1,2))
plot(pca_W.1$values[1:35], xlab='j', ylab='Eigenvalues')
plot(cumsum(pca_W.1$values)[1:35]/sum(pca_W.1$values), xlab='j', ylab='CPV', ylim=c(0.8, 1))
```

First two FPCs

```{r }
layout(cbind(1, 2))
plot(pca_W.1$harmonics[1, ], col=1, ylab='FPC1', ylim=c(-0.1, 0.08))
abline(h=0, lty=2)
plot(pca_W.1$harmonics[2, ], col=2, ylab='FPC2', ylim=c(-0.1, 0.08))
```

Plot of the FPCs as perturbation of the mean

```{r }
media <- mean.fd(data_W.fd.1)

par(mfrow=c(1,2))
plot(media, lwd=2, ylim=c(-25, 20), ylab='temperature', main='FPC1')
lines(media+pca_W.1$harmonics[1, ]*sqrt(pca_W.1$values[1]), col=2)
lines(media-pca_W.1$harmonics[1, ]*sqrt(pca_W.1$values[1]), col=3)
# variation in amplitude (more in winter than in summer)

plot(media, lwd=2, ylim=c(-20, 20), ylab='temperature', main='FPC2')
lines(media+pca_W.1$harmonics[2, ]*sqrt(pca_W.1$values[2]), col=2)
lines(media-pca_W.1$harmonics[2, ]*sqrt(pca_W.1$values[2]), col=3)
# temperate climate or not.
```

Command of the library `fda` that automatically does these plots

```{r }
par(mfrow=c(1, 2))
plot(pca_W.1, nx=100, pointplot=TRUE, harm=c(1, 2), expand=0, cycle=FALSE)
```

#### Smooth data (Choice 2)

```{r }
par(mfrow=c(1,1))
plot.fd(data_W.fd.2)

pca_W.2 <- pca.fd(data_W.fd.2, nharm=5, centerfns=TRUE)
```

Scree plot

```{r }
par(mfrow=c(1,2))
plot(pca_W.2$values, xlab='j', ylab='Eigenvalues')
plot(cumsum(pca_W.2$values)/sum(pca_W.2$values), xlab='j', ylab='CPV', ylim=c(0.8, 1))
```

First two FPCs

```{r }
layout(cbind(1, 2))
plot(pca_W.2$harmonics[1, ], col=1, ylab='FPC1', ylim=c(-0.1, 0.08))
abline(h=0, lty=2)
plot(pca_W.2$harmonics[2, ], col=2, ylab='FPC2', ylim=c(-0.1, 0.08))
```

Plot of the FPCs as perturbation of the mean

```{r }
media <- mean.fd(data_W.fd.2)

par(mfrow=c(1,2))

plot(media, lwd=2, ylim=c(-25, 20), ylab='temperature', main='PC1')
lines(media+pca_W.2$harmonics[1, ]*sqrt(pca_W.2$values[1]), col=2)
lines(media-pca_W.2$harmonics[1, ]*sqrt(pca_W.2$values[1]), col=3)

plot(media, lwd=2, ylim=c(-20, 20), ylab='temperature', main='PC2')
lines(media+pca_W.2$harmonics[2, ]*sqrt(pca_W.2$values[2]), col=2)
lines(media-pca_W.2$harmonics[2, ]*sqrt(pca_W.2$values[2]), col=3)
```

Similar interpretations as before.

Scatter plot of the scores.

```{r }
par(mfrow=c(1, 2))
plot(pca_W.1$scores[, 1], pca_W.1$scores[, 2], xlab="Scores FPC1", ylab="Scores FPC2", lwd=2)
points(pca_W.1$scores[35, 1], pca_W.1$scores[35, 2], col=2, lwd=4)

plot(pca_W.1$scores[, 1], pca_W.1$scores[, 2], type="n", xlab="Scores FPC1",
     ylab="Scores FPC2", xlim=c(-400, 250))
text(pca_W.1$scores[, 1], pca_W.1$scores[, 2], dimnames(data_W)[[2]], cex=1)
```

Outlier: Resolute (35)

```{r }
layout(1)
matplot(eval.1, type='l')
lines(eval.1[, 35], lwd=4, col=2) #temperature profile for Resolute

coord <- CanadianWeather$coordinates
coord[, 2] <- -coord[, 2]
plot(coord[, 2:1], col=1)
text(coord[, 2:1], rownames(coord))
```

Exercise: perform FPCA with Choice 3 of smoothing.

### FPCA on `lip`

```{r }
plot.fd(data_L.fd)

pca_L <- pca.fd(data_L.fd, nharm=5, centerfns=TRUE)
```

Scree plot

```{r }
par(mfrow=c(1,2))
plot(pca_L$values, xlab='j', ylab='Eigenvalues')
plot(cumsum(pca_L$values)/sum(pca_L$values), xlab='j', ylab='CPV', ylim=c(0.8, 1))
```

First three FPCs

```{r }
layout(cbind(1, 2, 3))
plot(pca_L$harmonics[1, ], col=1, ylab='FPC1', ylim=c(-0.09, 0.11))
plot(pca_L$harmonics[2, ], col=2, ylab='FPC2', ylim=c(-0.09, 0.11))
plot(pca_L$harmonics[3, ], col=3, ylab='FPC3', ylim=c(-0.09, 0.11))
```

Plot of the principal components as perturbation of the mean

```{r }
media <- mean.fd(data_L.fd)

plot(media, lwd=2, ylim=c(-10, 12), main='FPC1')
lines(media+pca_L$harmonic[1, ]*sqrt(pca_L$values[1]), col=2)
lines(media-pca_L$harmonic[1, ]*sqrt(pca_L$values[1]), col=3)
# variation in amplitude in the centre

plot(media, lwd=2, ylim=c(-10, 12), main='FPC2')
lines(media+pca_L$harmonic[2, ]*sqrt(pca_L$values[2]), col=2)
lines(media-pca_L$harmonic[2, ]*sqrt(pca_L$values[2]), col=3)
# horizontal translation - difference in timing

plot(media, lwd=2, ylim=c(-10, 12), main='FPC3')
lines(media+pca_L$harmonic[3, ]*sqrt(pca_L$values[3]), col=2)
lines(media-pca_L$harmonic[3, ]*sqrt(pca_L$values[3]), col=3)
# variation in amplitude at the boundaries of the domain
```

Command of the library `fda` that automatically does these plots

```{r }
par(mfrow=c(1, 3))
plot.pca.fd(pca_L, nx=100, pointplot=TRUE, harm=c(1, 2, 3), expand=0, cycle=FALSE)
```

Scores

```{r }
layout(cbind(1, 2, 3))
plot(pca_L$scores[, 1], pca_L$scores[, 2], xlab="Scores FPC1", ylab="Scores FPC2", lwd=2)
points(pca_L$scores[12, 1], pca_L$scores[12, 2], col=2, lwd=4)
points(pca_L$scores[9, 1], pca_L$scores[9, 2], col=3, lwd=4)
plot(pca_L$scores[, 1], pca_L$scores[, 3], xlab="Scores FPC1", ylab="Scores FPC3", lwd=2)
points(pca_L$scores[12, 1], pca_L$scores[12, 3], col=2, lwd=4)
points(pca_L$scores[9, 1], pca_L$scores[9, 3], col=3, lwd=4)
plot(pca_L$scores[, 2], pca_L$scores[, 3], xlab="Scores FPC2", ylab="Scores FPC3", lwd=2)
points(pca_L$scores[12, 2], pca_L$scores[12, 3], col=2, lwd=4)
points(pca_L$scores[9, 2], pca_L$scores[9, 3], col=3, lwd=4)

layout(1)
matplot(eval, type='l')
lines(eval[, 12], lwd=4, col=2)
lines(eval[, 9], lwd=4, col=3)
```
